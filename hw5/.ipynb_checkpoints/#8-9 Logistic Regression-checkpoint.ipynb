{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import e\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Line():\n",
    "    def __init__(self, p):\n",
    "        self.p1 = p[0]\n",
    "        self.p2 = p[1]\n",
    "        self.slope = (self.p1[1]-self.p2[1])/(self.p1[0]-self.p2[0])\n",
    "        self.b = self.p1[1]-self.slope*self.p1[0]\n",
    "        super().__init__()\n",
    "    def calculate(self,x):\n",
    "        return self.slope*x+self.b\n",
    "    def plot(self):\n",
    "        x = np.random.uniform(-1,1,10)\n",
    "        plt.plot(x,self.calculate(x))\n",
    "    def find_actual_y(self,points):\n",
    "        return [np.sign(self.calculate(p[0]) - p[1]) for p in points]\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "class LogisticRegression(Line):\n",
    "    def __init__(self,N):\n",
    "        self.weights = np.array([0,0,0])\n",
    "        self.n = .01\n",
    "        self.N = N\n",
    "        \n",
    "        self.create_line()\n",
    "        \n",
    "        X = [np.random.uniform(-1.0,1.0,2) for x in range(self.N)]\n",
    "        self.y = self.find_actual_y(X)\n",
    "        self.X = np.concatenate([[[1]for x in range(len(X))],X],axis=1)\n",
    "        \n",
    "        #self.run_sgd()\n",
    "        self.run_gradient_descent()\n",
    "        self.eout()\n",
    "        \n",
    "    def create_line(self):\n",
    "        p = [np.random.uniform(-1.0,1.0,2) for x in range(2)]\n",
    "        while p[0][0] == p[1][0] and p[0][1] == p[1][1]:\n",
    "            p = [np.random.uniform(-1.0,1.0,2) for x in range(2)]\n",
    "        super().__init__(p)\n",
    "  \n",
    "    def run_sgd(self):\n",
    "        self.num_iter = 0\n",
    "        cur_wdiff = 1\n",
    "        while True:\n",
    "            self.num_iter += 1\n",
    "            wt = self.weights\n",
    "            self.sgd_epoch()\n",
    "            wt1 = self.weights\n",
    "            if np.sqrt(sum((wt-wt1)**2)) <.01: #np.linalg.norm\n",
    "                break\n",
    "            \n",
    "        self.ein = self.cross_entropy_error(self.X,self.y)\n",
    "    \n",
    "    \n",
    "    def run_gradient_descent(self):\n",
    "        self.num_iter = 0\n",
    "        \n",
    "        for x in range(1000):\n",
    "            self.num_iter += 1\n",
    "            wt = self.weights\n",
    "            self.gradient_descent()\n",
    "            wt1 = self.weights\n",
    "            \n",
    "        \n",
    "        self.ein = self.cross_entropy_error(self.X,self.y)\n",
    "         \n",
    "        \n",
    "        \n",
    "####################################################\n",
    "        \n",
    "    def sdg_gradient(self,x,y):\n",
    "        w = self.weights\n",
    "        return (-y*x/(1+e**(y*np.matmul(x,w))))\n",
    "    \n",
    "    \n",
    "    def gradient(self):\n",
    "        w = self.weights\n",
    "        return sum([(-self.y[v]*self.X[v]/(1+e**(self.y[v]*np.matmul(self.X[v],w)))) for v in range(self.N)])/self.N\n",
    "         \n",
    "    \n",
    "####################################################\n",
    "    \n",
    "    \n",
    "    def gradient_descent(self):\n",
    "        gradient = -self.n *self.gradient()\n",
    "        self.weights = self.weights + gradient \n",
    "        \n",
    "    def sgd_epoch(self):\n",
    "        vals = list(range(self.N))\n",
    "        random.shuffle(vals)\n",
    "        for v in vals:\n",
    "            gradient = -self.n *self.sdg_gradient(self.X[v],self.y[v])\n",
    "            self.weights = self.weights + gradient  \n",
    "    \n",
    "    \n",
    "######################################################\n",
    "    \n",
    "    def cross_entropy_error(self,X,y):\n",
    "        w = self.weights\n",
    "        return sum([math.log(1+e**(-y[v]*np.matmul(X[v],w)), e) for v in range(len(X))])/len(X)\n",
    "    def calc(self,X):\n",
    "        return 1/(1+e**-np.matmul(X,self.weights))\n",
    "    \n",
    "    def eout(self):\n",
    "        X = [np.random.uniform(-1.0,1.0,2) for x in range(100)]\n",
    "        X = np.concatenate([[[1]for x in range(len(X))],X],axis=1)\n",
    "        y = self.find_actual_y(X)\n",
    "        self.eout = self.cross_entropy_error(X,y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class run_experiment():\n",
    "    def __init__(self,N, numEx):\n",
    "        self.N = N\n",
    "        self.numEx = numEx\n",
    "        self.run() \n",
    "    def run(self):\n",
    "        eouts = []\n",
    "        eins = []\n",
    "        num_iters = []\n",
    "        for x in range(self.numEx):\n",
    "            test = LogisticRegression(self.N)\n",
    "            eouts.append(test.eout)\n",
    "            eins.append(test.ein)\n",
    "            num_iters.append(test.num_iter)\n",
    "        Eout = np.mean(eouts)\n",
    "        NumIter = np.mean(num_iters)\n",
    "        Ein = np.mean(eins)\n",
    "        print(\"Eout Error %s\" % Eout)\n",
    "        print(\"Ein Error %s\" % Ein)\n",
    "        print(\"Num Iterations %s\" % NumIter) \n",
    "           \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eout Error 0.8903865048180757\n",
      "Ein Error 0.3465688744034626\n",
      "Num Iterations 1000.0\n"
     ]
    }
   ],
   "source": [
    "obj = run_experiment(100,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5, 11])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul([[1,2],[3,4]],[1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = random.shuffle([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.23606797749979"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_idxs = np.arange(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7320508075688772"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
