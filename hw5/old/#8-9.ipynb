{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import e\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Line():\n",
    "    def __init__(self, p):\n",
    "        self.p1 = p[0]\n",
    "        self.p2 = p[1]\n",
    "        self.slope = (self.p1[1]-self.p2[1])/(self.p1[0]-self.p2[0])\n",
    "        self.b = self.p1[1]-self.slope*self.p1[0]\n",
    "        super().__init__()\n",
    "    def calculate(self,x):\n",
    "        return self.slope*x+self.b\n",
    "    def plot(self):\n",
    "        x = np.random.uniform(-1,1,10)\n",
    "        plt.plot(x,self.calculate(x))\n",
    "    def find_actual_y(self,points):\n",
    "        return [np.sign(self.calculate(p[0]) - p[1]) for p in points]\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "class LogisticRegression(Line):\n",
    "    def __init__(self,N):\n",
    "        self.weights = np.array([0,0,0])\n",
    "        self.n = .01\n",
    "        self.N = N\n",
    "        \n",
    "        self.create_line()\n",
    "        \n",
    "        X = [np.random.uniform(-1.0,1.0,2) for x in range(self.N)]\n",
    "        \n",
    "        self.y = self.find_actual_y(self.X)\n",
    "        self.X = np.concatenate([[[1]for x in range(len(X))],X],axis=1)\n",
    "        self.run_sgb_w_epoch()\n",
    "        \n",
    "        \n",
    "    def create_line(self):\n",
    "        p = [np.random.uniform(-1.0,1.0,2) for x in range(2)]\n",
    "        while p[0][0] == p[1][0] and p[0][1] == p[1][1]:\n",
    "            p = [np.random.uniform(-1.0,1.0,2) for x in range(2)]\n",
    "        super().__init__(p)\n",
    "  \n",
    "    def run_sgb_w_epoch(self):\n",
    "        num_iter = 0\n",
    "        print(self.cross_entropy_error())\n",
    "        \n",
    "        for x in range(1000):\n",
    "            num_iter += 1\n",
    "            wt = self.weights\n",
    "            self.sgd_epoch()\n",
    "            wt1 = self.weights\n",
    "            if np.sqrt(sum((wt-wt1)**2)) <.01: #np.linalg.norm\n",
    "                break\n",
    "        \n",
    "        print(\"Error %s\" % self.cross_entropy_error())\n",
    "        print(\"num iterations %s\" % num_iter)\n",
    "        print(\"weights %s\" % self.weights)   \n",
    "        \n",
    "        #print(self.calc(self.X))\n",
    "    \n",
    "    \n",
    "    def run_gradient_descent(self):\n",
    "        num_iter = 0\n",
    "        print(self.cross_entropy_error())\n",
    "        \n",
    "        for x in range(1000):\n",
    "            num_iter += 1\n",
    "            wt = self.weights\n",
    "            #self.gradient_descent()\n",
    "            self.sgd_wout_epoch() \n",
    "            wt1 = self.weights\n",
    "            \n",
    "        \n",
    "        print(\"Error %s\" % self.cross_entropy_error())\n",
    "        print(\"num iterations %s\" % num_iter)\n",
    "        print(\"weights %s\" % self.weights)   \n",
    "        \n",
    "        \n",
    "####################################################\n",
    "        \n",
    "    def sdg_gradient(self,x,y):\n",
    "        w = self.weights\n",
    "        return -(-y*x/(1+e**(y*np.matmul(x,w))))\n",
    "    \n",
    "    \n",
    "    def gradient(self):\n",
    "        w = self.weights\n",
    "        return -sum([(-self.y[v]*self.X[v]/(1+e**(self.y[v]*np.matmul(self.X[v],w)))) for v in range(self.N)])/self.N\n",
    "         \n",
    "    \n",
    "####################################################\n",
    "    \n",
    "    \n",
    "    def gradient_descent(self):\n",
    "        gradient = self.n *self.gradient()\n",
    "        self.weights = self.weights + gradient \n",
    "        \n",
    "    def sgd_epoch(self):\n",
    "        vals = list(range(self.N))\n",
    "        random.shuffle(vals)\n",
    "        for v in vals:\n",
    "            gradient = self.n *self.sdg_gradient(self.X[v],self.y[v])\n",
    "            self.weights = self.weights + gradient  \n",
    "    \n",
    "    def sgd_wout_epoch(self):\n",
    "        val = random.randint(0,self.N-1)\n",
    "        x = self.X[val]\n",
    "        y = self.y[val]\n",
    "        gradient = self.n *self.sdg_gradient(self.X[val],self.y[val])\n",
    "        self.weights = self.weights + gradient  \n",
    "     \n",
    "    \n",
    "######################################################\n",
    "    \n",
    "    def cross_entropy_error(self):\n",
    "        w = self.weights\n",
    "        return sum([math.log(1+e**(-self.y[v]*np.matmul(self.X[v],w)), e) for v in range(self.N)])/self.N\n",
    "    def calc(self,X):\n",
    "        return 1/(1+e**-np.matmul(X,self.weights))\n",
    "    \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6931471805599458\n",
      "Error 0.009902229498993578\n",
      "num iterations 104\n",
      "weights [ 4.59879477  0.18009824 -0.11451627]\n"
     ]
    }
   ],
   "source": [
    "obj = LogisticRegression(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5, 11])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul([[1,2],[3,4]],[1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = random.shuffle([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.23606797749979"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_idxs = np.arange(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7320508075688772"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
